index = "idx"
corpus = "line.toml"
dataset = "data"
prefix = "."
stop-words = "search/agerman-stopwords.txt"
start-exceptions = "search/sentence-start-exceptions.txt"
end-exceptions = "search/sentence-end-exceptions.txt"
function-words = "search/function-words.txt"
punctuation = "search/sentence-punctuation.txt"

[[analyzers]]
method = "ngram-word"
ngram = 1
filter = [{type = "icu-tokenizer"}, {type = "lowercase"}]